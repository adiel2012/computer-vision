{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 14: Advanced Rendering Techniques\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/adiel2012/computer-vision/blob/main/chapter_14_advanced_rendering.ipynb)\n",
    "\n",
    "**Advanced rendering techniques** extend basic rendering with effects like ambient occlusion, subsurface scattering, volumetric rendering, and screen-space techniques. These methods add realism and atmosphere to rendered scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from typing import Tuple, List, Optional\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vec3:\n",
    "    def __init__(self, x: float = 0.0, y: float = 0.0, z: float = 0.0):\n",
    "        self.x, self.y, self.z = x, y, z\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        return Vec3(self.x + other.x, self.y + other.y, self.z + other.z)\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        return Vec3(self.x - other.x, self.y - other.y, self.z - other.z)\n",
    "    \n",
    "    def __mul__(self, scalar: float):\n",
    "        return Vec3(self.x * scalar, self.y * scalar, self.z * scalar)\n",
    "    \n",
    "    def __truediv__(self, scalar: float):\n",
    "        return Vec3(self.x / scalar, self.y / scalar, self.z / scalar)\n",
    "    \n",
    "    def __neg__(self):\n",
    "        return Vec3(-self.x, -self.y, -self.z)\n",
    "    \n",
    "    def dot(self, other) -> float:\n",
    "        return self.x * other.x + self.y * other.y + self.z * other.z\n",
    "    \n",
    "    def cross(self, other):\n",
    "        return Vec3(\n",
    "            self.y * other.z - self.z * other.y,\n",
    "            self.z * other.x - self.x * other.z,\n",
    "            self.x * other.y - self.y * other.x\n",
    "        )\n",
    "    \n",
    "    def length(self) -> float:\n",
    "        return math.sqrt(self.dot(self))\n",
    "    \n",
    "    def normalize(self):\n",
    "        l = self.length()\n",
    "        return self / l if l > 0 else Vec3(0, 0, 0)\n",
    "\n",
    "class Color:\n",
    "    def __init__(self, r: float = 0.0, g: float = 0.0, b: float = 0.0):\n",
    "        self.r, self.g, self.b = r, g, b\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        return Color(self.r + other.r, self.g + other.g, self.b + other.b)\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        if isinstance(other, Color):\n",
    "            return Color(self.r * other.r, self.g * other.g, self.b * other.b)\n",
    "        return Color(self.r * other, self.g * other, self.b * other)\n",
    "    \n",
    "    def __truediv__(self, scalar: float):\n",
    "        return Color(self.r / scalar, self.g / scalar, self.b / scalar)\n",
    "    \n",
    "    def clamp(self, min_val: float = 0.0, max_val: float = 1.0):\n",
    "        return Color(\n",
    "            max(min_val, min(max_val, self.r)),\n",
    "            max(min_val, min(max_val, self.g)),\n",
    "            max(min_val, min(max_val, self.b))\n",
    "        )\n",
    "    \n",
    "    def to_tuple(self) -> Tuple[float, float, float]:\n",
    "        return (self.r, self.g, self.b)\n",
    "\n",
    "print(\"✓ Base classes loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ambient Occlusion (AO)\n",
    "\n",
    "**Ambient Occlusion** approximates soft shadowing in crevices and corners.\n",
    "\n",
    "### Theory\n",
    "\n",
    "AO measures accessibility to ambient lighting:\n",
    "\n",
    "$$\n",
    "A(\\mathbf{p}) = \\frac{1}{\\pi} \\int_{\\Omega} V(\\mathbf{p}, \\omega) (\\mathbf{n} \\cdot \\omega) \\, d\\omega\n",
    "$$\n",
    "\n",
    "where $V(\\mathbf{p}, \\omega)$ is visibility (0 if occluded, 1 if visible).\n",
    "\n",
    "### Monte Carlo Approximation\n",
    "\n",
    "$$\n",
    "A(\\mathbf{p}) \\approx \\frac{1}{N} \\sum_{i=1}^{N} V(\\mathbf{p}, \\omega_i)\n",
    "$$\n",
    "\n",
    "Sample random directions in hemisphere, cast rays, count occlusions.\n",
    "\n",
    "### Screen Space Ambient Occlusion (SSAO)\n",
    "\n",
    "Fast approximation using depth buffer:\n",
    "1. Sample points around pixel in screen space\n",
    "2. Compare depths to determine occlusion\n",
    "3. Accumulate occlusion factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_in_hemisphere(normal: Vec3) -> Vec3:\n",
    "    \"\"\"Generate random direction in hemisphere\"\"\"\n",
    "    while True:\n",
    "        v = Vec3(random.uniform(-1, 1), random.uniform(-1, 1), random.uniform(-1, 1))\n",
    "        if v.length() < 1 and v.dot(normal) > 0:\n",
    "            return v.normalize()\n",
    "\n",
    "def compute_ambient_occlusion(point: Vec3, normal: Vec3, scene, \n",
    "                             num_samples: int = 16, max_dist: float = 1.0) -> float:\n",
    "    \"\"\"Compute ambient occlusion using ray casting\"\"\"\n",
    "    occlusion = 0.0\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        # Random direction in hemisphere\n",
    "        direction = random_in_hemisphere(normal)\n",
    "        \n",
    "        # Cast ray\n",
    "        ray_origin = point + normal * 0.001  # Offset to avoid self-intersection\n",
    "        \n",
    "        # Check for occlusion within max_dist\n",
    "        if scene.intersect_ao_ray(ray_origin, direction, max_dist):\n",
    "            occlusion += 1.0\n",
    "    \n",
    "    # Return accessibility (1 - occlusion)\n",
    "    return 1.0 - (occlusion / num_samples)\n",
    "\n",
    "print(\"✓ Ambient occlusion functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Subsurface Scattering (SSS)\n",
    "\n",
    "**Subsurface scattering** simulates light penetrating and scattering within translucent materials.\n",
    "\n",
    "### Dipole Approximation\n",
    "\n",
    "Approximate SSS using two point sources:\n",
    "\n",
    "$$\n",
    "S(r) = \\frac{\\alpha'}{4\\pi} \\left[ \\frac{e^{-\\sigma_t r_1}}{r_1^2} (\\sigma_t r_1 + 1) - \\frac{e^{-\\sigma_t r_2}}{r_2^2} (\\sigma_t r_2 + 1) \\right]\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $r_1, r_2$ are distances to real and virtual sources\n",
    "- $\\sigma_t$ is attenuation coefficient\n",
    "- $\\alpha'$ is reduced albedo\n",
    "\n",
    "### Simplified SSS\n",
    "\n",
    "Wrap lighting to simulate subsurface:\n",
    "\n",
    "$$\n",
    "L = \\max(0, \\frac{(\\mathbf{n} \\cdot \\mathbf{l}) + w}{1 + w})\n",
    "$$\n",
    "\n",
    "where $w$ is wrap amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsurface_scattering_wrap(n_dot_l: float, wrap: float = 0.5) -> float:\n",
    "    \"\"\"Simple wrap lighting for SSS approximation\"\"\"\n",
    "    return max(0.0, (n_dot_l + wrap) / (1.0 + wrap))\n",
    "\n",
    "def translucent_shadow(thickness: float, light_intensity: float, \n",
    "                      absorption: float = 2.0) -> float:\n",
    "    \"\"\"Compute light transmission through translucent material\"\"\"\n",
    "    # Beer-Lambert law\n",
    "    transmission = math.exp(-absorption * thickness)\n",
    "    return light_intensity * transmission\n",
    "\n",
    "print(\"✓ Subsurface scattering functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Volumetric Rendering\n",
    "\n",
    "**Volumetric rendering** handles participating media like fog, smoke, and clouds.\n",
    "\n",
    "### Volume Rendering Equation\n",
    "\n",
    "$$\n",
    "L(\\mathbf{x}, \\omega) = \\int_0^D T(t) \\sigma_s(\\mathbf{x} + t\\omega) L_s(\\mathbf{x} + t\\omega, \\omega) \\, dt + T(D) L_0\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $T(t) = e^{-\\int_0^t \\sigma_t(s) ds}$ is transmittance\n",
    "- $\\sigma_s$ is scattering coefficient\n",
    "- $\\sigma_t = \\sigma_s + \\sigma_a$ (scattering + absorption)\n",
    "- $L_s$ is scattered radiance\n",
    "- $L_0$ is background radiance\n",
    "\n",
    "### Ray Marching\n",
    "\n",
    "Discrete approximation:\n",
    "\n",
    "$$\n",
    "L \\approx \\sum_{i=1}^{N} T_i \\cdot \\sigma_s(\\mathbf{x}_i) \\cdot L_s(\\mathbf{x}_i) \\cdot \\Delta t + T_N \\cdot L_0\n",
    "$$\n",
    "\n",
    "where $T_i = \\prod_{j=1}^{i-1} (1 - \\sigma_t(\\mathbf{x}_j) \\Delta t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VolumetricMedium:\n",
    "    \"\"\"Homogeneous volumetric medium\"\"\"\n",
    "    def __init__(self, density: float, albedo: Color, phase_g: float = 0.0):\n",
    "        self.density = density  # sigma_t\n",
    "        self.albedo = albedo    # sigma_s / sigma_t\n",
    "        self.phase_g = phase_g  # Henyey-Greenstein parameter\n",
    "    \n",
    "    def phase_function(self, cos_theta: float) -> float:\n",
    "        \"\"\"Henyey-Greenstein phase function\"\"\"\n",
    "        g = self.phase_g\n",
    "        denom = 1.0 + g * g - 2.0 * g * cos_theta\n",
    "        return (1.0 - g * g) / (4.0 * math.pi * denom ** 1.5)\n",
    "\n",
    "def ray_march_volume(ray_start: Vec3, ray_dir: Vec3, t_max: float,\n",
    "                    medium: VolumetricMedium, light_dir: Vec3,\n",
    "                    light_color: Color, num_steps: int = 64) -> Color:\n",
    "    \"\"\"Ray marching through volumetric medium\"\"\"\n",
    "    dt = t_max / num_steps\n",
    "    \n",
    "    accumulated_color = Color(0, 0, 0)\n",
    "    transmittance = 1.0\n",
    "    \n",
    "    for i in range(num_steps):\n",
    "        t = (i + 0.5) * dt\n",
    "        pos = ray_start + ray_dir * t\n",
    "        \n",
    "        # Density at current position (could be spatially varying)\n",
    "        density = medium.density\n",
    "        \n",
    "        # Scattering\n",
    "        cos_theta = ray_dir.dot(light_dir)\n",
    "        phase = medium.phase_function(cos_theta)\n",
    "        \n",
    "        # In-scattering contribution\n",
    "        scattering = density * phase\n",
    "        inscatter = light_color * (medium.albedo * scattering * transmittance * dt)\n",
    "        \n",
    "        accumulated_color = accumulated_color + inscatter\n",
    "        \n",
    "        # Update transmittance\n",
    "        transmittance *= math.exp(-density * dt)\n",
    "    \n",
    "    return accumulated_color\n",
    "\n",
    "print(\"✓ Volumetric rendering functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bloom and Glow\n",
    "\n",
    "**Bloom** simulates light bleeding from bright areas.\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "1. Extract bright pixels: $L_{bright} = \\max(0, L - threshold)$\n",
    "2. Blur bright pixels (Gaussian)\n",
    "3. Composite: $L_{final} = L + intensity \\cdot L_{blur}$\n",
    "\n",
    "### Gaussian Blur\n",
    "\n",
    "$$\n",
    "G(x, y) = \\frac{1}{2\\pi\\sigma^2} e^{-\\frac{x^2 + y^2}{2\\sigma^2}}\n",
    "$$\n",
    "\n",
    "Separable: blur horizontally then vertically for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bright_pixels(image: np.ndarray, threshold: float = 0.8) -> np.ndarray:\n",
    "    \"\"\"Extract pixels brighter than threshold\"\"\"\n",
    "    bright = np.maximum(0, image - threshold)\n",
    "    return bright\n",
    "\n",
    "def gaussian_blur_1d(image: np.ndarray, sigma: float = 2.0, \n",
    "                    axis: int = 0) -> np.ndarray:\n",
    "    \"\"\"1D Gaussian blur along axis\"\"\"\n",
    "    # Create Gaussian kernel\n",
    "    kernel_size = int(6 * sigma + 1)\n",
    "    if kernel_size % 2 == 0:\n",
    "        kernel_size += 1\n",
    "    \n",
    "    kernel_half = kernel_size // 2\n",
    "    kernel = np.zeros(kernel_size)\n",
    "    \n",
    "    for i in range(kernel_size):\n",
    "        x = i - kernel_half\n",
    "        kernel[i] = math.exp(-(x * x) / (2 * sigma * sigma))\n",
    "    \n",
    "    kernel /= kernel.sum()\n",
    "    \n",
    "    # Apply convolution\n",
    "    from scipy.ndimage import convolve1d\n",
    "    return convolve1d(image, kernel, axis=axis, mode='reflect')\n",
    "\n",
    "def apply_bloom(image: np.ndarray, threshold: float = 0.8, \n",
    "               intensity: float = 0.5, blur_sigma: float = 5.0) -> np.ndarray:\n",
    "    \"\"\"Apply bloom effect to image\"\"\"\n",
    "    # Extract bright pixels\n",
    "    bright = extract_bright_pixels(image, threshold)\n",
    "    \n",
    "    # Blur (separable Gaussian)\n",
    "    blurred = gaussian_blur_1d(bright, blur_sigma, axis=0)\n",
    "    blurred = gaussian_blur_1d(blurred, blur_sigma, axis=1)\n",
    "    \n",
    "    # Composite\n",
    "    result = image + intensity * blurred\n",
    "    return np.clip(result, 0, 1)\n",
    "\n",
    "print(\"✓ Bloom functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Depth of Field (Post-Process)\n",
    "\n",
    "**Depth of Field** can be approximated in post-processing using depth buffer.\n",
    "\n",
    "### Circle of Confusion\n",
    "\n",
    "$$\n",
    "CoC = \\frac{A |d - d_{focus}|}{d(d_{focus} - f)}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $A$ is aperture\n",
    "- $d$ is object distance\n",
    "- $d_{focus}$ is focus distance\n",
    "- $f$ is focal length\n",
    "\n",
    "Blur radius proportional to circle of confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coc(depth: float, focus_distance: float, \n",
    "               aperture: float = 0.1, focal_length: float = 1.0) -> float:\n",
    "    \"\"\"Compute circle of confusion size\"\"\"\n",
    "    if depth <= 0:\n",
    "        return 0\n",
    "    \n",
    "    coc = aperture * abs(depth - focus_distance) / (depth * (focus_distance - focal_length))\n",
    "    return min(coc, 10.0)  # Clamp max blur\n",
    "\n",
    "print(\"✓ Depth of field functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Ambient Occlusion Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple AO visualization\n",
    "width, height = 400, 400\n",
    "ao_image = np.ones((height, width))\n",
    "\n",
    "# Simulate cavity - darker in corners\n",
    "for j in range(height):\n",
    "    for i in range(width):\n",
    "        # Distance from edges\n",
    "        dx = min(i, width - i) / width\n",
    "        dy = min(j, height - j) / height\n",
    "        dist = min(dx, dy)\n",
    "        \n",
    "        # Darken corners\n",
    "        ao = 0.3 + 0.7 * (dist / 0.5) ** 0.5\n",
    "        ao_image[j, i] = min(1.0, ao)\n",
    "\n",
    "# Apply to surface\n",
    "base_color = np.ones((height, width, 3)) * [0.8, 0.6, 0.4]\n",
    "ao_applied = base_color * ao_image[:, :, np.newaxis]\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "ax1.imshow(base_color)\n",
    "ax1.set_title('Base Color')\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2.imshow(ao_image, cmap='gray')\n",
    "ax2.set_title('Ambient Occlusion (white=accessible)')\n",
    "ax2.axis('off')\n",
    "\n",
    "ax3.imshow(ao_applied)\n",
    "ax3.set_title('With AO Applied')\n",
    "ax3.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice darker areas in corners (occluded regions).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Volumetric Fog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render scene with volumetric fog\n",
    "width, height = 400, 300\n",
    "fog_image = np.zeros((height, width, 3))\n",
    "\n",
    "# Fog medium\n",
    "fog = VolumetricMedium(density=0.1, albedo=Color(0.8, 0.8, 0.9), phase_g=0.3)\n",
    "light_dir = Vec3(0.5, 0.7, 0.3).normalize()\n",
    "light_color = Color(1.0, 0.95, 0.8)\n",
    "\n",
    "for j in range(height):\n",
    "    if j % 50 == 0:\n",
    "        print(f\"Row {j}/{height}\")\n",
    "    \n",
    "    for i in range(width):\n",
    "        # Ray through pixel\n",
    "        u = (2.0 * i / width - 1.0)\n",
    "        v = (1.0 - 2.0 * j / height)\n",
    "        \n",
    "        ray_start = Vec3(u * 2, v * 1.5, 3)\n",
    "        ray_dir = Vec3(0, 0, -1)\n",
    "        \n",
    "        # Background gradient\n",
    "        t = 0.5 * (v + 1.0)\n",
    "        background = Color(0.5, 0.7, 1.0) * t + Color(1.0, 1.0, 1.0) * (1.0 - t)\n",
    "        \n",
    "        # Ray march through fog\n",
    "        fog_color = ray_march_volume(ray_start, ray_dir, 6.0, fog, \n",
    "                                     light_dir, light_color, num_steps=32)\n",
    "        \n",
    "        # Composite with background\n",
    "        final = fog_color + background * 0.3\n",
    "        \n",
    "        fog_image[j, i] = final.clamp(0, 1).to_tuple()\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(fog_image)\n",
    "plt.title('Volumetric Fog using Ray Marching')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Volumetric fog with light scattering.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Bloom Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test image with bright spots\n",
    "test_image = np.zeros((300, 400, 3))\n",
    "\n",
    "# Add some bright lights\n",
    "centers = [(100, 150), (300, 150), (200, 80), (200, 220)]\n",
    "for cx, cy in centers:\n",
    "    for j in range(300):\n",
    "        for i in range(400):\n",
    "            dist = math.sqrt((i - cx)**2 + (j - cy)**2)\n",
    "            if dist < 20:\n",
    "                intensity = max(0, 1.0 - dist / 20)\n",
    "                test_image[j, i] = [intensity * 1.5, intensity * 1.2, intensity]\n",
    "\n",
    "# Apply bloom\n",
    "try:\n",
    "    from scipy.ndimage import convolve1d\n",
    "    bloomed = apply_bloom(test_image, threshold=0.6, intensity=0.8, blur_sigma=8.0)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    ax1.imshow(test_image)\n",
    "    ax1.set_title('Original (Bright Lights)')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2.imshow(bloomed)\n",
    "    ax2.set_title('With Bloom Effect')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Bloom creates glow around bright areas.\")\n",
    "except ImportError:\n",
    "    print(\"scipy not available - bloom effect requires scipy.ndimage\")\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.imshow(test_image)\n",
    "    plt.title('Test Image (install scipy for bloom)')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Advanced rendering techniques** add realism beyond basic shading:\n",
    "\n",
    "### Techniques Covered\n",
    "\n",
    "1. **Ambient Occlusion**\n",
    "   - Contact shadows in crevices\n",
    "   - Screen-space (SSAO) or ray-traced\n",
    "   - Enhances depth perception\n",
    "\n",
    "2. **Subsurface Scattering**\n",
    "   - Light penetration in translucent materials\n",
    "   - Essential for skin, wax, marble\n",
    "   - Dipole approximation or wrap lighting\n",
    "\n",
    "3. **Volumetric Rendering**\n",
    "   - Participating media (fog, smoke, clouds)\n",
    "   - Ray marching through volume\n",
    "   - Phase functions for anisotropic scattering\n",
    "\n",
    "4. **Bloom/Glow**\n",
    "   - Light bleeding from bright sources\n",
    "   - Extract-blur-composite pipeline\n",
    "   - Simulates camera/eye response\n",
    "\n",
    "5. **Depth of Field**\n",
    "   - Focal blur effects\n",
    "   - Circle of confusion\n",
    "   - Can be ray-traced or post-processed\n",
    "\n",
    "### Applications\n",
    "\n",
    "- **Film/Animation**: Realistic lighting and atmosphere\n",
    "- **Games**: Real-time approximations (SSAO, fast SSS)\n",
    "- **Visualization**: Scientific rendering, medical imaging\n",
    "- **VR/AR**: Immersive environments\n",
    "\n",
    "### Performance Considerations\n",
    "\n",
    "- **AO**: Expensive if ray-traced; SSAO is real-time friendly\n",
    "- **SSS**: Full dipole is slow; approximations for real-time\n",
    "- **Volumetrics**: Ray marching is costly; optimize step count\n",
    "- **Post-processing**: Generally fast (bloom, DoF)\n",
    "\n",
    "These techniques are essential for production-quality rendering."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
