{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: 3D Transformations and Viewing Pipeline\n",
    "\n",
    "## The Complete Pipeline Implementation\n",
    "\n",
    "This notebook covers:\n",
    "- 3D transformation implementation\n",
    "- Camera system implementation\n",
    "- Projection implementation\n",
    "- Viewport transformation\n",
    "- Complete transformation pipeline\n",
    "\n",
    "**Key References:** Marschner & Shirley Ch. 7-8, Gambetta Ch. 5-6"
   ]
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\nimport math\nfrom typing import Tuple, List\n\nprint(\"✓ Imports loaded\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class Vec3:\n    \"\"\"3D Vector class\"\"\"\n    def __init__(self, x=0.0, y=0.0, z=0.0):\n        self.x = float(x)\n        self.y = float(y)\n        self.z = float(z)\n    \n    def __add__(self, other):\n        return Vec3(self.x + other.x, self.y + other.y, self.z + other.z)\n    \n    def __sub__(self, other):\n        return Vec3(self.x - other.x, self.y - other.y, self.z - other.z)\n    \n    def __mul__(self, scalar):\n        return Vec3(self.x * scalar, self.y * scalar, self.z * scalar)\n    \n    def __truediv__(self, scalar):\n        return Vec3(self.x / scalar, self.y / scalar, self.z / scalar)\n    \n    def dot(self, other):\n        return self.x * other.x + self.y * other.y + self.z * other.z\n    \n    def cross(self, other):\n        return Vec3(\n            self.y * other.z - self.z * other.y,\n            self.z * other.x - self.x * other.z,\n            self.x * other.y - self.y * other.x\n        )\n    \n    def length(self):\n        return math.sqrt(self.x**2 + self.y**2 + self.z**2)\n    \n    def normalize(self):\n        l = self.length()\n        return self / l if l > 0 else Vec3(0, 0, 0)\n    \n    def __repr__(self):\n        return f\"Vec3({self.x:.3f}, {self.y:.3f}, {self.z:.3f})\"\n\nclass Mat4:\n    \"\"\"4x4 Matrix for transformations\"\"\"\n    def __init__(self, data=None):\n        if data is None:\n            self.m = [[1,0,0,0], [0,1,0,0], [0,0,1,0], [0,0,0,1]]\n        else:\n            self.m = [list(row) for row in data]\n    \n    @staticmethod\n    def zeros():\n        return Mat4([[0,0,0,0], [0,0,0,0], [0,0,0,0], [0,0,0,0]])\n    \n    def __getitem__(self, key):\n        return self.m[key]\n    \n    def __matmul__(self, other):\n        \"\"\"Matrix multiplication\"\"\"\n        result = Mat4.zeros()\n        for i in range(4):\n            for j in range(4):\n                result.m[i][j] = sum(self.m[i][k] * other.m[k][j] for k in range(4))\n        return result\n    \n    def mul_vec3(self, v: Vec3) -> Vec3:\n        \"\"\"Transform Vec3 (assuming w=1)\"\"\"\n        x = self.m[0][0]*v.x + self.m[0][1]*v.y + self.m[0][2]*v.z + self.m[0][3]\n        y = self.m[1][0]*v.x + self.m[1][1]*v.y + self.m[1][2]*v.z + self.m[1][3]\n        z = self.m[2][0]*v.x + self.m[2][1]*v.y + self.m[2][2]*v.z + self.m[2][3]\n        w = self.m[3][0]*v.x + self.m[3][1]*v.y + self.m[3][2]*v.z + self.m[3][3]\n        \n        if w != 0 and w != 1:\n            return Vec3(x/w, y/w, z/w)\n        return Vec3(x, y, z)\n    \n    def __repr__(self):\n        lines = []\n        for row in self.m:\n            lines.append(\"  \" + \" \".join(f\"{x:8.3f}\" for x in row))\n        return \"Mat4(\\n\" + \"\\n\".join(lines) + \"\\n)\"\n\nprint(\"✓ Vec3 and Mat4 classes loaded\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## 1. Viewing Pipeline - Theory\n\n### 1.1 The Graphics Pipeline\n\nThe **viewing transformation pipeline** converts 3D world coordinates to 2D screen coordinates:\n\n$$\\boxed{\\text{Object Space}} \\xrightarrow{\\text{Model}} \\boxed{\\text{World Space}} \\xrightarrow{\\text{View}} \\boxed{\\text{Camera Space}} \\xrightarrow{\\text{Projection}} \\boxed{\\text{Clip Space}} \\xrightarrow{\\text{Perspective Divide}} \\boxed{\\text{NDC}} \\xrightarrow{\\text{Viewport}} \\boxed{\\text{Screen Space}}$$\n\n**Pipeline stages:**\n\n1. **Model Transform:** Position objects in world space\n2. **View Transform:** Transform to camera space\n3. **Projection:** Apply perspective or orthographic projection\n4. **Perspective Divide:** Homogeneous to Cartesian conversion\n5. **Viewport Transform:** Map to screen coordinates\n\n### 1.2 Camera/View Transformation\n\n**Goal:** Transform world coordinates to camera-centric coordinates.\n\n**Camera definition:**\n- **Position** $\\mathbf{e}$ (eye point)\n- **Look-at point** $\\mathbf{t}$ (target)\n- **Up vector** $\\mathbf{u}_{\\text{world}}$ (typically $(0, 1, 0)$)\n\n**Camera coordinate frame:**\n\n$$\\mathbf{w} = \\frac{\\mathbf{e} - \\mathbf{t}}{\\|\\mathbf{e} - \\mathbf{t}\\|} \\quad \\text{(backward, RH system)}$$\n\n$$\\mathbf{u} = \\frac{\\mathbf{u}_{\\text{world}} \\times \\mathbf{w}}{\\|\\mathbf{u}_{\\text{world}} \\times \\mathbf{w}\\|} \\quad \\text{(right)}$$\n\n$$\\mathbf{v} = \\mathbf{w} \\times \\mathbf{u} \\quad \\text{(up)}$$\n\n**View matrix (look-at):**\n\n$$\\mathbf{M}_{\\text{view}} = \\begin{pmatrix}\nu_x & u_y & u_z & -\\mathbf{u} \\cdot \\mathbf{e} \\\\\nv_x & v_y & v_z & -\\mathbf{v} \\cdot \\mathbf{e} \\\\\nw_x & w_y & w_z & -\\mathbf{w} \\cdot \\mathbf{e} \\\\\n0 & 0 & 0 & 1\n\\end{pmatrix}$$\n\nThis is equivalent to: $\\mathbf{M}_{\\text{view}} = \\mathbf{R} \\mathbf{T}$\n\nwhere $\\mathbf{T}$ translates by $-\\mathbf{e}$ and $\\mathbf{R}$ rotates to align axes.\n\n### 1.3 Projection Transformations\n\n#### Perspective Projection\n\n**Perspective projection** simulates human vision (objects farther away appear smaller).\n\n**Frustum parameters:**\n- Field of view (FOV): $\\theta$ (vertical angle)\n- Aspect ratio: $a = \\frac{\\text{width}}{\\text{height}}$\n- Near plane: $n$\n- Far plane: $f$\n\n**Perspective matrix:**\n\n$$\\mathbf{M}_{\\text{persp}} = \\begin{pmatrix}\n\\frac{1}{a \\tan(\\theta/2)} & 0 & 0 & 0 \\\\\n0 & \\frac{1}{\\tan(\\theta/2)} & 0 & 0 \\\\\n0 & 0 & -\\frac{f+n}{f-n} & -\\frac{2fn}{f-n} \\\\\n0 & 0 & -1 & 0\n\\end{pmatrix}$$\n\n**After projection:** Divide by $w$ to get NDC (Normalized Device Coordinates):\n\n$$\\text{NDC} = \\left(\\frac{x}{w}, \\frac{y}{w}, \\frac{z}{w}\\right), \\quad (x,y,z) \\in [-1, 1]^3$$\n\n#### Orthographic Projection\n\n**Orthographic projection** preserves parallel lines (no perspective).\n\n**Parameters:** Left $l$, right $r$, bottom $b$, top $t$, near $n$, far $f$\n\n$$\\mathbf{M}_{\\text{ortho}} = \\begin{pmatrix}\n\\frac{2}{r-l} & 0 & 0 & -\\frac{r+l}{r-l} \\\\\n0 & \\frac{2}{t-b} & 0 & -\\frac{t+b}{t-b} \\\\\n0 & 0 & -\\frac{2}{f-n} & -\\frac{f+n}{f-n} \\\\\n0 & 0 & 0 & 1\n\\end{pmatrix}$$\n\n### 1.4 Viewport Transformation\n\n**Goal:** Map NDC $[-1, 1]^2$ to screen coordinates $[0, W] \\times [0, H]$\n\n$$x_{\\text{screen}} = \\frac{W}{2}(x_{\\text{NDC}} + 1)$$\n\n$$y_{\\text{screen}} = \\frac{H}{2}(y_{\\text{NDC}} + 1)$$\n\nOr in matrix form:\n\n$$\\mathbf{M}_{\\text{viewport}} = \\begin{pmatrix}\nW/2 & 0 & 0 & W/2 \\\\\n0 & H/2 & 0 & H/2 \\\\\n0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 1\n\\end{pmatrix}$$",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def look_at(eye: Vec3, target: Vec3, up: Vec3) -> Mat4:\n    \"\"\"Create view (camera) matrix using look-at transformation\"\"\"\n    w = (eye - target).normalize()\n    u = up.cross(w).normalize()\n    v = w.cross(u)\n    \n    mat = Mat4([\n        [u.x, u.y, u.z, -u.dot(eye)],\n        [v.x, v.y, v.z, -v.dot(eye)],\n        [w.x, w.y, w.z, -w.dot(eye)],\n        [0,   0,   0,   1]\n    ])\n    return mat\n\ndef perspective(fov_y: float, aspect: float, near: float, far: float) -> Mat4:\n    \"\"\"Create perspective projection matrix\"\"\"\n    tan_half_fov = math.tan(fov_y / 2.0)\n    \n    mat = Mat4.zeros()\n    mat[0][0] = 1.0 / (aspect * tan_half_fov)\n    mat[1][1] = 1.0 / tan_half_fov\n    mat[2][2] = -(far + near) / (far - near)\n    mat[2][3] = -(2.0 * far * near) / (far - near)\n    mat[3][2] = -1.0\n    return mat\n\ndef orthographic(left: float, right: float, bottom: float, top: float, \n                 near: float, far: float) -> Mat4:\n    \"\"\"Create orthographic projection matrix\"\"\"\n    mat = Mat4.zeros()\n    mat[0][0] = 2.0 / (right - left)\n    mat[1][1] = 2.0 / (top - bottom)\n    mat[2][2] = -2.0 / (far - near)\n    mat[0][3] = -(right + left) / (right - left)\n    mat[1][3] = -(top + bottom) / (top - bottom)\n    mat[2][3] = -(far + near) / (far - near)\n    mat[3][3] = 1.0\n    return mat\n\nclass Camera:\n    \"\"\"Camera class with view and projection\"\"\"\n    def __init__(self, position: Vec3, target: Vec3, up: Vec3,\n                 fov: float = math.radians(60), aspect: float = 16/9,\n                 near: float = 0.1, far: float = 100.0):\n        self.position = position\n        self.target = target\n        self.up = up\n        self.fov = fov\n        self.aspect = aspect\n        self.near = near\n        self.far = far\n        self.update()\n    \n    def update(self):\n        \"\"\"Recompute view and projection matrices\"\"\"\n        self.view_matrix = look_at(self.position, self.target, self.up)\n        self.projection_matrix = perspective(self.fov, self.aspect, self.near, self.far)\n        self.vp_matrix = self.projection_matrix @ self.view_matrix\n    \n    def world_to_screen(self, point: Vec3, width: int, height: int) -> Tuple[float, float, float]:\n        \"\"\"Transform point from world space to screen coordinates\"\"\"\n        x = self.vp_matrix.m[0][0]*point.x + self.vp_matrix.m[0][1]*point.y + self.vp_matrix.m[0][2]*point.z + self.vp_matrix.m[0][3]\n        y = self.vp_matrix.m[1][0]*point.x + self.vp_matrix.m[1][1]*point.y + self.vp_matrix.m[1][2]*point.z + self.vp_matrix.m[1][3]\n        z = self.vp_matrix.m[2][0]*point.x + self.vp_matrix.m[2][1]*point.y + self.vp_matrix.m[2][2]*point.z + self.vp_matrix.m[2][3]\n        w = self.vp_matrix.m[3][0]*point.x + self.vp_matrix.m[3][1]*point.y + self.vp_matrix.m[3][2]*point.z + self.vp_matrix.m[3][3]\n        \n        if w != 0:\n            x /= w\n            y /= w\n            z /= w\n        \n        screen_x = (x + 1) * width / 2\n        screen_y = (y + 1) * height / 2\n        return (screen_x, screen_y, z)\n\nprint(\"✓ Helper functions and Camera class loaded\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Example 1: Visualize Projection Differences\nprint(\"Example 1: Perspective vs Orthographic Projection\\n\")\n\n# Create a grid of points in 3D\ngrid_points = []\nfor x in range(-2, 3):\n    for z in range(1, 6):\n        grid_points.append(Vec3(x, 0, -z))\n\n# Perspective camera\npersp_cam = Camera(\n    position=Vec3(0, 2, 0),\n    target=Vec3(0, 0, -3),\n    up=Vec3(0, 1, 0),\n    fov=math.radians(60),\n    aspect=1.0\n)\n\n# Orthographic projection\northo_proj = orthographic(-5, 5, -5, 5, 0.1, 10)\nview = look_at(Vec3(0, 2, 0), Vec3(0, 0, -3), Vec3(0, 1, 0))\n\nprint(\"Grid point projections:\")\nprint(\"\\nPerspective:\")\nfor i, p in enumerate(grid_points[:5]):  # Show first 5\n    sx, sy, depth = persp_cam.world_to_screen(p, 800, 800)\n    print(f\"  {p} -> ({sx:.1f}, {sy:.1f})\")\n\nprint(\"\\nOrthographic (same points):\")\nfor i, p in enumerate(grid_points[:5]):\n    # Apply ortho projection manually\n    p_view = view.mul_vec3(p)\n    p_proj = ortho_proj.mul_vec3(p_view)\n    sx = (p_proj.x + 1) * 400\n    sy = (p_proj.y + 1) * 400\n    print(f\"  {p} -> ({sx:.1f}, {sy:.1f})\")\n\n# Example 2: Camera Animation Path\nprint(\"\\n\\nExample 2: Camera Animation\\n\")\n\ndef animate_camera_orbit(target: Vec3, radius: float, num_frames: int):\n    \"\"\"Generate camera positions for orbital animation\"\"\"\n    positions = []\n    \n    for i in range(num_frames):\n        angle = 2 * math.pi * i / num_frames\n        x = target.x + radius * math.cos(angle)\n        z = target.z + radius * math.sin(angle)\n        y = target.y + radius * 0.3  # Slight elevation\n        \n        positions.append(Vec3(x, y, z))\n    \n    return positions\n\n# Generate orbital path\norbit_positions = animate_camera_orbit(Vec3(0, 0, 0), radius=5, num_frames=8)\n\nprint(\"Orbital camera path (8 frames):\")\nfor i, pos in enumerate(orbit_positions):\n    cam = Camera(pos, Vec3(0, 0, 0), Vec3(0, 1, 0))\n    print(f\"  Frame {i}: camera at {pos}\")\n\n# Example 3: FOV Comparison\nprint(\"\\n\\nExample 3: Field of View Effects\\n\")\n\ntest_point = Vec3(2, 0, -5)\n\nfov_values = [30, 60, 90, 120]\n\nprint(f\"Same point {test_point} with different FOVs:\")\nfor fov_deg in fov_values:\n    cam = Camera(\n        position=Vec3(0, 0, 0),\n        target=Vec3(0, 0, -1),\n        up=Vec3(0, 1, 0),\n        fov=math.radians(fov_deg),\n        aspect=16/9\n    )\n    \n    sx, sy, depth = cam.world_to_screen(test_point, 1920, 1080)\n    print(f\"  FOV={fov_deg}°: screen=({sx:.1f}, {sy:.1f})\")\n\n# Example 4: Complete Pipeline Visualization\nprint(\"\\n\\nExample 4: Complete Transformation Pipeline\\n\")\n\n# Create a cube's vertices\ncube_vertices = [\n    Vec3(-1, -1, -5), Vec3(1, -1, -5), Vec3(1, 1, -5), Vec3(-1, 1, -5),  # Front\n    Vec3(-1, -1, -7), Vec3(1, -1, -7), Vec3(1, 1, -7), Vec3(-1, 1, -7),  # Back\n]\n\n# Create camera\ncam = Camera(\n    position=Vec3(0, 2, 0),\n    target=Vec3(0, 0, -6),\n    up=Vec3(0, 1, 0),\n    fov=math.radians(60),\n    aspect=16/9\n)\n\nprint(\"Cube vertices through the pipeline:\")\nprint(\"(showing first 4 vertices)\")\nfor i, v in enumerate(cube_vertices[:4]):\n    # World space\n    print(f\"\\nVertex {i}: {v}\")\n    \n    # View space\n    v_view = cam.view_matrix.mul_vec3(v)\n    print(f\"  View space: {v_view}\")\n    \n    # Screen space\n    sx, sy, depth = cam.world_to_screen(v, 1920, 1080)\n    print(f\"  Screen space: ({sx:.1f}, {sy:.1f}), depth={depth:.3f}\")\n\n# Example 5: Frustum Visualization\nprint(\"\\n\\nExample 5: View Frustum Analysis\\n\")\n\ndef is_in_frustum(point: Vec3, cam: Camera) -> bool:\n    \"\"\"Check if point is inside view frustum (simplified)\"\"\"\n    # Transform to clip space\n    x = cam.vp_matrix.m[0][0]*point.x + cam.vp_matrix.m[0][1]*point.y + cam.vp_matrix.m[0][2]*point.z + cam.vp_matrix.m[0][3]\n    y = cam.vp_matrix.m[1][0]*point.x + cam.vp_matrix.m[1][1]*point.y + cam.vp_matrix.m[1][2]*point.z + cam.vp_matrix.m[1][3]\n    z = cam.vp_matrix.m[2][0]*point.x + cam.vp_matrix.m[2][1]*point.y + cam.vp_matrix.m[2][2]*point.z + cam.vp_matrix.m[2][3]\n    w = cam.vp_matrix.m[3][0]*point.x + cam.vp_matrix.m[3][1]*point.y + cam.vp_matrix.m[3][2]*point.z + cam.vp_matrix.m[3][3]\n    \n    # Check if in NDC bounds after perspective divide\n    if w <= 0:\n        return False\n    \n    x /= w\n    y /= w\n    z /= w\n    \n    return (-1 <= x <= 1) and (-1 <= y <= 1) and (-1 <= z <= 1)\n\n# Test points at various locations\ntest_locations = [\n    (Vec3(0, 0, -5), \"center of view\"),\n    (Vec3(10, 0, -5), \"far right\"),\n    (Vec3(0, 0, -0.05), \"too close (before near plane)\"),\n    (Vec3(0, 0, -150), \"too far (beyond far plane)\"),\n    (Vec3(0, 0, 5), \"behind camera\"),\n]\n\ncam = Camera(Vec3(0, 0, 0), Vec3(0, 0, -1), Vec3(0, 1, 0))\n\nprint(\"Frustum culling test:\")\nfor point, desc in test_locations:\n    in_frustum = is_in_frustum(point, cam)\n    status = \"VISIBLE\" if in_frustum else \"CULLED\"\n    print(f\"  {point} ({desc}): {status}\")\n\nprint(\"\\n✓ Chapter 4 Complete!\")\nprint(\"\\nIn this chapter, you learned:\")\nprint(\"  • Complete viewing transformation pipeline\")\nprint(\"  • View matrix (look-at transformation)\")\nprint(\"  • Perspective and orthographic projection\")\nprint(\"  • Viewport transformation\")\nprint(\"  • Camera class with orbit controls\")\nprint(\"  • World-to-screen coordinate transformation\")\nprint(\"  • Frustum culling basics\")\nprint(\"\\nNext Chapter: Visibility and Hidden Surface Removal\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## 3. Practical Examples\n\nComplete demonstrations of the viewing pipeline.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class Camera:\n    \"\"\"Camera class with view and projection\"\"\"\n    \n    def __init__(self, position: Vec3, target: Vec3, up: Vec3,\n                 fov: float = math.radians(60), aspect: float = 16/9,\n                 near: float = 0.1, far: float = 100.0):\n        \"\"\"\n        Initialize camera\n        \n        Args:\n            position: Camera position\n            target: Point camera looks at\n            up: World up vector\n            fov: Vertical field of view (radians)\n            aspect: Aspect ratio (width/height)\n            near: Near clipping plane\n            far: Far clipping plane\n        \"\"\"\n        self.position = position\n        self.target = target\n        self.up = up\n        self.fov = fov\n        self.aspect = aspect\n        self.near = near\n        self.far = far\n        \n        # Compute view and projection matrices\n        self.update()\n    \n    def update(self):\n        \"\"\"Recompute view and projection matrices\"\"\"\n        self.view_matrix = look_at(self.position, self.target, self.up)\n        self.projection_matrix = perspective(self.fov, self.aspect, self.near, self.far)\n        \n        # Combined view-projection matrix\n        self.vp_matrix = self.projection_matrix @ self.view_matrix\n    \n    def world_to_screen(self, point: Vec3, width: int, height: int) -> Tuple[float, float, float]:\n        \"\"\"\n        Transform point from world space to screen coordinates\n        \n        Returns:\n            (screen_x, screen_y, depth)\n        \"\"\"\n        # Apply view-projection\n        x = self.vp_matrix.m[0][0]*point.x + self.vp_matrix.m[0][1]*point.y + self.vp_matrix.m[0][2]*point.z + self.vp_matrix.m[0][3]\n        y = self.vp_matrix.m[1][0]*point.x + self.vp_matrix.m[1][1]*point.y + self.vp_matrix.m[1][2]*point.z + self.vp_matrix.m[1][3]\n        z = self.vp_matrix.m[2][0]*point.x + self.vp_matrix.m[2][1]*point.y + self.vp_matrix.m[2][2]*point.z + self.vp_matrix.m[2][3]\n        w = self.vp_matrix.m[3][0]*point.x + self.vp_matrix.m[3][1]*point.y + self.vp_matrix.m[3][2]*point.z + self.vp_matrix.m[3][3]\n        \n        # Perspective divide\n        if w != 0:\n            x /= w\n            y /= w\n            z /= w\n        \n        # Viewport transform\n        screen_x = (x + 1) * width / 2\n        screen_y = (y + 1) * height / 2\n        \n        return (screen_x, screen_y, z)\n    \n    def __repr__(self):\n        return f\"Camera(pos={self.position}, target={self.target}, fov={math.degrees(self.fov):.1f}°)\"\n\nclass OrbitCamera(Camera):\n    \"\"\"Orbit camera that rotates around a target\"\"\"\n    \n    def __init__(self, target: Vec3, distance: float, azimuth: float = 0, elevation: float = 0,\n                 fov: float = math.radians(60), aspect: float = 16/9):\n        \"\"\"\n        Initialize orbit camera\n        \n        Args:\n            target: Point to orbit around\n            distance: Distance from target\n            azimuth: Horizontal angle (radians)\n            elevation: Vertical angle (radians)\n        \"\"\"\n        self.target = target\n        self.distance = distance\n        self.azimuth = azimuth\n        self.elevation = elevation\n        \n        # Compute initial position\n        position = self._compute_position()\n        \n        super().__init__(position, target, Vec3(0, 1, 0), fov, aspect)\n    \n    def _compute_position(self) -> Vec3:\n        \"\"\"Compute camera position from spherical coordinates\"\"\"\n        x = self.target.x + self.distance * math.cos(self.elevation) * math.cos(self.azimuth)\n        y = self.target.y + self.distance * math.sin(self.elevation)\n        z = self.target.z + self.distance * math.cos(self.elevation) * math.sin(self.azimuth)\n        return Vec3(x, y, z)\n    \n    def rotate(self, delta_azimuth: float, delta_elevation: float):\n        \"\"\"Rotate camera around target\"\"\"\n        self.azimuth += delta_azimuth\n        self.elevation += delta_elevation\n        \n        # Clamp elevation to avoid gimbal lock\n        self.elevation = max(-math.pi/2 + 0.01, min(math.pi/2 - 0.01, self.elevation))\n        \n        # Update position\n        self.position = self._compute_position()\n        self.update()\n    \n    def zoom(self, delta: float):\n        \"\"\"Zoom in/out\"\"\"\n        self.distance += delta\n        self.distance = max(0.1, self.distance)  # Minimum distance\n        \n        self.position = self._compute_position()\n        self.update()\n\n# Test Camera\nprint(\"Testing Camera System:\\n\")\n\n# Create a camera\ncam = Camera(\n    position=Vec3(5, 3, 5),\n    target=Vec3(0, 0, 0),\n    up=Vec3(0, 1, 0),\n    fov=math.radians(60),\n    aspect=16/9\n)\n\nprint(f\"Camera: {cam}\\n\")\n\n# Transform some points\ntest_points = [\n    Vec3(0, 0, 0),\n    Vec3(1, 0, 0),\n    Vec3(0, 1, 0),\n    Vec3(0, 0, 1),\n]\n\nwidth, height = 1920, 1080\n\nprint(\"World to Screen Transformations:\")\nfor p in test_points:\n    screen_x, screen_y, depth = cam.world_to_screen(p, width, height)\n    print(f\"  {p} -> screen({screen_x:.1f}, {screen_y:.1f}), depth={depth:.3f}\")\n\n# Test orbit camera\nprint(\"\\n\\nTesting Orbit Camera:\\n\")\n\norbit_cam = OrbitCamera(\n    target=Vec3(0, 0, 0),\n    distance=10,\n    azimuth=math.radians(45),\n    elevation=math.radians(30)\n)\n\nprint(f\"Orbit Camera: {orbit_cam}\")\nprint(f\"Initial position: {orbit_cam.position}\")\n\n# Rotate\norbit_cam.rotate(math.radians(15), math.radians(10))\nprint(f\"After rotation: {orbit_cam.position}\")\n\n# Zoom\norbit_cam.zoom(-2)\nprint(f\"After zoom: {orbit_cam.position}, distance={orbit_cam.distance:.2f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## 2. Camera System - Implementation",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## 2. Camera System - Theory\n\n### 2.1 Camera Class Design\n\nA **camera** encapsulates:\n- **Position** and **orientation** in world space\n- **Projection parameters** (FOV, aspect, near/far planes)\n- **View and projection matrices**\n\n### 2.2 Camera Controls\n\n**Orbit camera:** Rotate around a target point\n- **Azimuth** $\\phi$: Horizontal rotation angle\n- **Elevation** $\\theta$: Vertical rotation angle  \n- **Distance** $d$: Distance from target\n\nCamera position:\n$$\\mathbf{e} = \\mathbf{t} + d(\\cos\\theta\\cos\\phi, \\sin\\theta, \\cos\\theta\\sin\\phi)$$\n\n**FPS camera:** First-person movement\n- **Forward/backward:** Move along view direction\n- **Strafe left/right:** Move along right vector\n- **Yaw/pitch:** Rotate view direction",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def look_at(eye: Vec3, target: Vec3, up: Vec3) -> Mat4:\n    \"\"\"\n    Create view (camera) matrix using look-at transformation\n    \n    Args:\n        eye: Camera position\n        target: Point camera is looking at\n        up: World up vector\n    \n    Returns:\n        View matrix\n    \"\"\"\n    # Compute camera coordinate frame\n    w = (eye - target).normalize()  # Camera looks down -z, so w points backward\n    u = up.cross(w).normalize()      # Right vector\n    v = w.cross(u)                   # Up vector (recomputed for orthogonality)\n    \n    # Create view matrix\n    mat = Mat4([\n        [u.x, u.y, u.z, -u.dot(eye)],\n        [v.x, v.y, v.z, -v.dot(eye)],\n        [w.x, w.y, w.z, -w.dot(eye)],\n        [0,   0,   0,   1]\n    ])\n    \n    return mat\n\ndef perspective(fov_y: float, aspect: float, near: float, far: float) -> Mat4:\n    \"\"\"\n    Create perspective projection matrix\n    \n    Args:\n        fov_y: Vertical field of view in radians\n        aspect: Aspect ratio (width / height)\n        near: Near clipping plane\n        far: Far clipping plane\n    \n    Returns:\n        Perspective projection matrix\n    \"\"\"\n    tan_half_fov = math.tan(fov_y / 2.0)\n    \n    mat = Mat4.zeros()\n    mat[0][0] = 1.0 / (aspect * tan_half_fov)\n    mat[1][1] = 1.0 / tan_half_fov\n    mat[2][2] = -(far + near) / (far - near)\n    mat[2][3] = -(2.0 * far * near) / (far - near)\n    mat[3][2] = -1.0\n    \n    return mat\n\ndef orthographic(left: float, right: float, bottom: float, top: float, \n                 near: float, far: float) -> Mat4:\n    \"\"\"\n    Create orthographic projection matrix\n    \n    Args:\n        left, right: Horizontal bounds\n        bottom, top: Vertical bounds\n        near, far: Depth bounds\n    \n    Returns:\n        Orthographic projection matrix\n    \"\"\"\n    mat = Mat4.zeros()\n    mat[0][0] = 2.0 / (right - left)\n    mat[1][1] = 2.0 / (top - bottom)\n    mat[2][2] = -2.0 / (far - near)\n    mat[0][3] = -(right + left) / (right - left)\n    mat[1][3] = -(top + bottom) / (top - bottom)\n    mat[2][3] = -(far + near) / (far - near)\n    mat[3][3] = 1.0\n    \n    return mat\n\ndef viewport(width: int, height: int) -> Mat4:\n    \"\"\"\n    Create viewport transformation matrix\n    Maps from NDC [-1,1]^2 to screen coordinates [0,W]x[0,H]\n    \n    Args:\n        width: Screen width in pixels\n        height: Screen height in pixels\n    \n    Returns:\n        Viewport matrix\n    \"\"\"\n    mat = Mat4([\n        [width/2,  0,         0, width/2],\n        [0,        height/2,  0, height/2],\n        [0,        0,         1, 0],\n        [0,        0,         0, 1]\n    ])\n    \n    return mat\n\n# Test transformation matrices\nprint(\"Testing Viewing Transformations:\\n\")\n\n# Create a view matrix\neye = Vec3(5, 5, 5)\ntarget = Vec3(0, 0, 0)\nup = Vec3(0, 1, 0)\n\nview_mat = look_at(eye, target, up)\nprint(\"View Matrix (look-at):\")\nprint(view_mat)\nprint()\n\n# Test perspective projection\nfov = math.radians(60)\naspect = 16.0 / 9.0\nnear = 0.1\nfar = 100.0\n\npersp_mat = perspective(fov, aspect, near, far)\nprint(\"Perspective Projection Matrix:\")\nprint(persp_mat)\nprint()\n\n# Test orthographic projection\northo_mat = orthographic(-10, 10, -10, 10, 0.1, 100)\nprint(\"Orthographic Projection Matrix:\")\nprint(ortho_mat)\nprint()\n\n# Test viewport transformation\nviewport_mat = viewport(1920, 1080)\nprint(\"Viewport Matrix (1920x1080):\")\nprint(viewport_mat)\nprint()\n\n# Transform a point through the pipeline\npoint = Vec3(1, 1, -10)\nprint(f\"Original point (world space): {point}\")\n\n# Apply view transform\npoint_view = view_mat.mul_vec3(point)\nprint(f\"After view transform: {point_view}\")\n\n# Apply projection (perspective)\n# Note: This produces homogeneous coordinates, need to divide by w\nx = persp_mat.m[0][0]*point_view.x + persp_mat.m[0][3]\ny = persp_mat.m[1][1]*point_view.y + persp_mat.m[1][3]\nz = persp_mat.m[2][2]*point_view.z + persp_mat.m[2][3]\nw = persp_mat.m[3][2]*point_view.z\n\nprint(f\"After projection (clip space): ({x:.3f}, {y:.3f}, {z:.3f}, w={w:.3f})\")\n\n# Perspective divide to get NDC\nif w != 0:\n    ndc = Vec3(x/w, y/w, z/w)\n    print(f\"After perspective divide (NDC): {ndc}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## 1. Viewing Pipeline - Implementation",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## Setup and Imports",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your implementation starts here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}