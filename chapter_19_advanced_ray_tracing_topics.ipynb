{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 19: Advanced Ray Tracing Topics\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/adiel2012/computer-vision/blob/main/chapter_19_advanced_ray_tracing_topics.ipynb)\n",
    "\n",
    "**Modern ray tracing** encompasses real-time rendering, denoising, hybrid methods, and cutting-edge research. This chapter covers techniques enabling real-time ray tracing in games and interactive applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from typing import Tuple, List\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Real-Time Ray Tracing\n",
    "\n",
    "**Real-time RT** targets 30-60 FPS with limited samples per pixel.\n",
    "\n",
    "### Challenges\n",
    "\n",
    "- **Low sample counts**: 1-4 SPP → high noise\n",
    "- **Tight frame budgets**: 16-33ms per frame\n",
    "- **Complex scenes**: Millions of triangles\n",
    "- **Dynamic content**: Moving objects, changing lights\n",
    "\n",
    "### Strategies\n",
    "\n",
    "1. **Hybrid rendering**: Rasterization + selective RT\n",
    "2. **Aggressive denoising**: Temporal + spatial filters\n",
    "3. **Hardware acceleration**: RTX cores, BVH hardware\n",
    "4. **Adaptive sampling**: More samples where needed\n",
    "5. **Temporal reuse**: Accumulate across frames\n",
    "\n",
    "### Performance Budget (60 FPS)\n",
    "\n",
    "$$\n",
    "16.67 \\text{ ms/frame} = \\text{G-buffer} + \\text{RT} + \\text{denoise} + \\text{compose}\n",
    "$$\n",
    "\n",
    "Typical split:\n",
    "- G-buffer: 3-5 ms\n",
    "- Ray tracing: 5-8 ms  \n",
    "- Denoising: 3-5 ms\n",
    "- Composition: 1-2 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealTimeConfig:\n",
    "    \"\"\"Configuration for real-time ray tracing\"\"\"\n",
    "    def __init__(self):\n",
    "        # Sample counts\n",
    "        self.shadow_rays_per_pixel = 1  # Hard shadows\n",
    "        self.reflection_rays = 1  # Single reflection\n",
    "        self.ao_rays = 1  # Ambient occlusion\n",
    "        self.gi_rays = 1  # Indirect lighting\n",
    "        \n",
    "        # Quality vs performance\n",
    "        self.max_bounces = 3  # Limited recursion\n",
    "        self.russian_roulette_depth = 2\n",
    "        \n",
    "        # Resolution scaling\n",
    "        self.rt_resolution_scale = 0.5  # Half-res RT\n",
    "        \n",
    "        # Temporal accumulation\n",
    "        self.temporal_alpha = 0.05  # Blend with history\n",
    "        self.max_accumulation = 64  # frames\n",
    "\n",
    "def estimate_frame_time(config, width, height):\n",
    "    \"\"\"Estimate rendering time (simplified)\"\"\"\n",
    "    rt_width = int(width * config.rt_resolution_scale)\n",
    "    rt_height = int(height * config.rt_resolution_scale)\n",
    "    \n",
    "    total_rays = rt_width * rt_height * (\n",
    "        config.shadow_rays_per_pixel +\n",
    "        config.reflection_rays +\n",
    "        config.ao_rays +\n",
    "        config.gi_rays\n",
    "    )\n",
    "    \n",
    "    # Assume 1M rays/ms on RTX GPU\n",
    "    rays_per_ms = 1_000_000\n",
    "    rt_time_ms = total_rays / rays_per_ms\n",
    "    \n",
    "    # Add denoising (~20% of RT time)\n",
    "    denoise_time_ms = rt_time_ms * 0.2\n",
    "    \n",
    "    # Add G-buffer (~5ms)\n",
    "    gbuffer_time_ms = 5.0\n",
    "    \n",
    "    total_time_ms = gbuffer_time_ms + rt_time_ms + denoise_time_ms\n",
    "    \n",
    "    return {\n",
    "        'total_ms': total_time_ms,\n",
    "        'fps': 1000.0 / total_time_ms if total_time_ms > 0 else 0,\n",
    "        'rt_ms': rt_time_ms,\n",
    "        'denoise_ms': denoise_time_ms,\n",
    "        'gbuffer_ms': gbuffer_time_ms\n",
    "    }\n",
    "\n",
    "# Example\n",
    "config = RealTimeConfig()\n",
    "perf = estimate_frame_time(config, 1920, 1080)\n",
    "print(f\"Estimated performance: {perf['fps']:.1f} FPS\")\n",
    "print(f\"Frame time breakdown:\")\n",
    "print(f\"  G-buffer:  {perf['gbuffer_ms']:.2f} ms\")\n",
    "print(f\"  Ray trace: {perf['rt_ms']:.2f} ms\")\n",
    "print(f\"  Denoise:   {perf['denoise_ms']:.2f} ms\")\n",
    "print(f\"  Total:     {perf['total_ms']:.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Temporal Accumulation\n",
    "\n",
    "**Temporal accumulation** blends current frame with history.\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "$$\n",
    "C_t = \\alpha C_{\\text{current}} + (1 - \\alpha) C_{\\text{history}}\n",
    "$$\n",
    "\n",
    "where $\\alpha \\in [0, 1]$ controls blend factor.\n",
    "\n",
    "### Motion Vectors\n",
    "\n",
    "Track pixel motion between frames:\n",
    "\n",
    "$$\n",
    "\\mathbf{v} = \\mathbf{p}_{\\text{current}} - \\mathbf{p}_{\\text{previous}}\n",
    "$$\n",
    "\n",
    "Reproject previous frame:\n",
    "$$\n",
    "\\mathbf{p}_{\\text{history}} = \\mathbf{p}_{\\text{current}} - \\mathbf{v}\n",
    "$$\n",
    "\n",
    "### Disocclusion Detection\n",
    "\n",
    "Detect when history is invalid:\n",
    "- Depth discontinuity\n",
    "- Normal change\n",
    "- Off-screen history\n",
    "- New geometry\n",
    "\n",
    "Increase $\\alpha$ for disoccluded pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_accumulation(current, history, motion_vectors, alpha=0.05):\n",
    "    \"\"\"Temporal accumulation with motion vectors\"\"\"\n",
    "    height, width = current.shape[:2]\n",
    "    result = np.zeros_like(current)\n",
    "    \n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            # Get motion vector\n",
    "            mv = motion_vectors[y, x]\n",
    "            \n",
    "            # Reproject to previous frame\n",
    "            prev_x = x - int(mv[0])\n",
    "            prev_y = y - int(mv[1])\n",
    "            \n",
    "            # Check if history is valid\n",
    "            if (0 <= prev_x < width and 0 <= prev_y < height):\n",
    "                # Blend current with history\n",
    "                hist_color = history[prev_y, prev_x]\n",
    "                result[y, x] = alpha * current[y, x] + (1 - alpha) * hist_color\n",
    "            else:\n",
    "                # No valid history (disocclusion)\n",
    "                result[y, x] = current[y, x]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Simulate temporal accumulation\n",
    "def demonstrate_temporal_accumulation():\n",
    "    \"\"\"Show effect of temporal accumulation on noise\"\"\"\n",
    "    size = 256\n",
    "    num_frames = 30\n",
    "    \n",
    "    # Base image (clean)\n",
    "    base = np.zeros((size, size, 3))\n",
    "    for y in range(size):\n",
    "        for x in range(size):\n",
    "            base[y, x] = [x/size, y/size, 0.5]\n",
    "    \n",
    "    # No temporal accumulation (just current noisy frame)\n",
    "    noisy_single = base + np.random.normal(0, 0.2, base.shape)\n",
    "    noisy_single = np.clip(noisy_single, 0, 1)\n",
    "    \n",
    "    # With temporal accumulation\n",
    "    accumulated = base.copy()\n",
    "    for frame in range(num_frames):\n",
    "        # Add noise (simulating low SPP)\n",
    "        noisy = base + np.random.normal(0, 0.2, base.shape)\n",
    "        noisy = np.clip(noisy, 0, 1)\n",
    "        \n",
    "        # Accumulate (no motion for simplicity)\n",
    "        alpha = 1.0 / (frame + 1)  # Decreasing alpha\n",
    "        accumulated = alpha * noisy + (1 - alpha) * accumulated\n",
    "    \n",
    "    return noisy_single, accumulated\n",
    "\n",
    "print(\"✓ Temporal accumulation loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Spatiotemporal Denoising (SVGF)\n",
    "\n",
    "**SVGF** (Spatiotemporal Variance-Guided Filtering) for real-time.\n",
    "\n",
    "### Algorithm Steps\n",
    "\n",
    "1. **Temporal accumulation**: Blend with reprojected history\n",
    "2. **Variance estimation**: Track sample variance\n",
    "3. **Edge-stopping à-trous wavelet**: Multi-scale spatial filter\n",
    "4. **Guided by variance**: Larger kernel where more variance\n",
    "\n",
    "### Edge-Stopping Function\n",
    "\n",
    "$$\n",
    "w(\\mathbf{p}, \\mathbf{q}) = w_z \\cdot w_n \\cdot w_l\n",
    "$$\n",
    "\n",
    "- $w_z$: depth similarity\n",
    "- $w_n$: normal similarity\n",
    "- $w_l$: luminance similarity\n",
    "\n",
    "### Variance-Guided Kernel\n",
    "\n",
    "$$\n",
    "\\sigma_{\\text{kernel}} = k \\cdot \\sqrt{\\text{var}(\\mathbf{p})}\n",
    "$$\n",
    "\n",
    "Larger filter for noisier regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_stopping_weight(center_val, neighbor_val, sigma):\n",
    "    \"\"\"Compute edge-stopping weight\"\"\"\n",
    "    diff = np.linalg.norm(center_val - neighbor_val)\n",
    "    return math.exp(-(diff * diff) / (2 * sigma * sigma))\n",
    "\n",
    "def atrous_wavelet_filter(image, normals=None, depth=None, iteration=0):\n",
    "    \"\"\"À-trous wavelet filter (edge-aware)\"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    result = np.zeros_like(image)\n",
    "    \n",
    "    # Kernel step size (2^iteration)\n",
    "    step = 2 ** iteration\n",
    "    \n",
    "    # 3x3 kernel offsets\n",
    "    kernel_offsets = [\n",
    "        (-1, -1), (0, -1), (1, -1),\n",
    "        (-1,  0), (0,  0), (1,  0),\n",
    "        (-1,  1), (0,  1), (1,  1)\n",
    "    ]\n",
    "    \n",
    "    # Gaussian kernel weights\n",
    "    kernel_weights = np.array([\n",
    "        1, 2, 1,\n",
    "        2, 4, 2,\n",
    "        1, 2, 1\n",
    "    ], dtype=float) / 16.0\n",
    "    \n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            center_color = image[y, x]\n",
    "            \n",
    "            sum_weight = 0.0\n",
    "            sum_color = np.zeros(3)\n",
    "            \n",
    "            for i, (dx, dy) in enumerate(kernel_offsets):\n",
    "                nx = x + dx * step\n",
    "                ny = y + dy * step\n",
    "                \n",
    "                # Clamp to bounds\n",
    "                nx = np.clip(nx, 0, width - 1)\n",
    "                ny = np.clip(ny, 0, height - 1)\n",
    "                \n",
    "                neighbor_color = image[ny, nx]\n",
    "                \n",
    "                # Spatial weight (Gaussian)\n",
    "                w_spatial = kernel_weights[i]\n",
    "                \n",
    "                # Color similarity weight\n",
    "                w_color = edge_stopping_weight(center_color, neighbor_color, 0.2)\n",
    "                \n",
    "                # Combined weight\n",
    "                weight = w_spatial * w_color\n",
    "                \n",
    "                sum_weight += weight\n",
    "                sum_color += weight * neighbor_color\n",
    "            \n",
    "            if sum_weight > 0:\n",
    "                result[y, x] = sum_color / sum_weight\n",
    "            else:\n",
    "                result[y, x] = center_color\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"✓ À-trous wavelet filter loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reservoir Sampling (ReSTIR)\n",
    "\n",
    "**ReSTIR** (Reservoir-based Spatiotemporal Importance Resampling) for efficient direct lighting.\n",
    "\n",
    "### Problem\n",
    "\n",
    "With thousands of lights, testing all is expensive:\n",
    "\n",
    "$$\n",
    "L = \\sum_{i=1}^N L_i\n",
    "$$\n",
    "\n",
    "### Solution: Weighted Reservoir Sampling\n",
    "\n",
    "Maintain $M$ samples in reservoir, update with new sample:\n",
    "\n",
    "$$\n",
    "w_{\\text{sum}} \\leftarrow w_{\\text{sum}} + w_i\n",
    "$$\n",
    "$$\n",
    "\\text{Accept with probability } \\frac{w_i}{w_{\\text{sum}}}\n",
    "$$\n",
    "\n",
    "### Temporal Reuse\n",
    "\n",
    "Reuse previous frame's reservoirs:\n",
    "1. Reproject to previous frame\n",
    "2. Combine reservoirs\n",
    "3. Validate with visibility\n",
    "\n",
    "### Spatial Reuse\n",
    "\n",
    "Share reservoirs with neighbors:\n",
    "- More effective samples\n",
    "- Correlation across pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Reservoir:\n",
    "    \"\"\"Weighted reservoir for importance sampling\"\"\"\n",
    "    sample_id: int = -1  # Currently held sample\n",
    "    weight_sum: float = 0.0  # Sum of weights\n",
    "    num_samples: int = 0  # M (number seen)\n",
    "    \n",
    "    def update(self, new_sample_id: int, weight: float) -> bool:\n",
    "        \"\"\"Update reservoir with new sample\"\"\"\n",
    "        self.weight_sum += weight\n",
    "        self.num_samples += 1\n",
    "        \n",
    "        # Accept with probability w / w_sum\n",
    "        if random.random() < (weight / self.weight_sum):\n",
    "            self.sample_id = new_sample_id\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def get_contribution_weight(self) -> float:\n",
    "        \"\"\"Get weight for final contribution\"\"\"\n",
    "        if self.num_samples == 0:\n",
    "            return 0.0\n",
    "        return self.weight_sum / self.num_samples\n",
    "\n",
    "def restir_light_sampling(lights, num_candidates=32):\n",
    "    \"\"\"ReSTIR light sampling (simplified)\"\"\"\n",
    "    reservoir = Reservoir()\n",
    "    \n",
    "    # Sample candidates\n",
    "    for _ in range(num_candidates):\n",
    "        # Randomly select light\n",
    "        light_id = random.randint(0, len(lights) - 1)\n",
    "        \n",
    "        # Compute weight (simplified: just intensity)\n",
    "        weight = lights[light_id]['intensity']\n",
    "        \n",
    "        # Update reservoir\n",
    "        reservoir.update(light_id, weight)\n",
    "    \n",
    "    return reservoir\n",
    "\n",
    "# Example\n",
    "lights = [{'intensity': random.random() * 10} for _ in range(1000)]\n",
    "reservoir = restir_light_sampling(lights)\n",
    "print(f\"Selected light {reservoir.sample_id} from {len(lights)} lights\")\n",
    "print(f\"Contribution weight: {reservoir.get_contribution_weight():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hybrid Rendering\n",
    "\n",
    "**Hybrid rendering** combines rasterization and ray tracing.\n",
    "\n",
    "### Typical Pipeline\n",
    "\n",
    "1. **G-buffer pass** (rasterization):\n",
    "   - Depth\n",
    "   - Normals\n",
    "   - Albedo\n",
    "   - Roughness/Metallic\n",
    "\n",
    "2. **Ray tracing passes** (selective):\n",
    "   - Shadows\n",
    "   - Reflections\n",
    "   - Ambient occlusion\n",
    "   - Global illumination (1 bounce)\n",
    "\n",
    "3. **Denoising**:\n",
    "   - Separate denoisers per effect\n",
    "   - Guided by G-buffer\n",
    "\n",
    "4. **Composition**:\n",
    "   - Combine all layers\n",
    "   - Post-processing\n",
    "\n",
    "### Benefits\n",
    "\n",
    "- Fast primary visibility (rasterization)\n",
    "- High-quality secondary effects (RT)\n",
    "- Scalable quality/performance trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridRenderer:\n",
    "    \"\"\"Hybrid rasterization + ray tracing renderer (conceptual)\"\"\"\n",
    "    \n",
    "    def render_frame(self, scene, camera, width, height):\n",
    "        \"\"\"Render frame with hybrid approach\"\"\"\n",
    "        \n",
    "        # 1. G-buffer pass (rasterization)\n",
    "        gbuffer = self.rasterize_gbuffer(scene, camera, width, height)\n",
    "        # gbuffer contains: depth, normal, albedo, roughness\n",
    "        \n",
    "        # 2. Ray tracing passes (selective)\n",
    "        shadows = self.trace_shadows(gbuffer, scene, samples_per_pixel=1)\n",
    "        reflections = self.trace_reflections(gbuffer, scene, samples_per_pixel=1)\n",
    "        ao = self.trace_ambient_occlusion(gbuffer, scene, samples_per_pixel=1)\n",
    "        gi = self.trace_global_illumination(gbuffer, scene, samples_per_pixel=1)\n",
    "        \n",
    "        # 3. Denoise each layer\n",
    "        shadows_clean = self.denoise(shadows, gbuffer)\n",
    "        reflections_clean = self.denoise(reflections, gbuffer)\n",
    "        ao_clean = self.denoise(ao, gbuffer)\n",
    "        gi_clean = self.denoise(gi, gbuffer)\n",
    "        \n",
    "        # 4. Compose final image\n",
    "        final = self.compose(\n",
    "            gbuffer,\n",
    "            shadows_clean,\n",
    "            reflections_clean,\n",
    "            ao_clean,\n",
    "            gi_clean\n",
    "        )\n",
    "        \n",
    "        return final\n",
    "    \n",
    "    def rasterize_gbuffer(self, scene, camera, width, height):\n",
    "        # Rasterize geometry to G-buffer\n",
    "        return {'depth': None, 'normal': None, 'albedo': None}\n",
    "    \n",
    "    def trace_shadows(self, gbuffer, scene, samples_per_pixel):\n",
    "        # Ray trace shadows\n",
    "        return None\n",
    "    \n",
    "    def trace_reflections(self, gbuffer, scene, samples_per_pixel):\n",
    "        # Ray trace reflections\n",
    "        return None\n",
    "    \n",
    "    def trace_ambient_occlusion(self, gbuffer, scene, samples_per_pixel):\n",
    "        # Ray trace AO\n",
    "        return None\n",
    "    \n",
    "    def trace_global_illumination(self, gbuffer, scene, samples_per_pixel):\n",
    "        # Ray trace 1-bounce GI\n",
    "        return None\n",
    "    \n",
    "    def denoise(self, noisy, gbuffer):\n",
    "        # Spatiotemporal denoising\n",
    "        return noisy\n",
    "    \n",
    "    def compose(self, gbuffer, shadows, reflections, ao, gi):\n",
    "        # Combine all layers\n",
    "        return None\n",
    "\n",
    "print(\"✓ Hybrid renderer concept loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Temporal Accumulation Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate temporal accumulation effect\n",
    "noisy_single, accumulated = demonstrate_temporal_accumulation()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "axes[0].imshow(noisy_single)\n",
    "axes[0].set_title('Single Frame (1 SPP, Noisy)')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(accumulated)\n",
    "axes[1].set_title('Temporal Accumulation (30 frames)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Temporal accumulation significantly reduces noise over time!\")\n",
    "print(\"This enables 1 SPP real-time ray tracing with acceptable quality.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Advanced ray tracing** for real-time and production:\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Real-Time Ray Tracing**\n",
    "   - 1-4 SPP per frame\n",
    "   - 30-60 FPS target\n",
    "   - Hybrid rasterization + RT\n",
    "   - Hardware acceleration (RTX)\n",
    "\n",
    "2. **Temporal Accumulation**\n",
    "   - Blend with previous frames\n",
    "   - Motion vector reprojection\n",
    "   - Disocclusion detection\n",
    "   - Exponential moving average\n",
    "\n",
    "3. **Spatiotemporal Denoising (SVGF)**\n",
    "   - Temporal accumulation first\n",
    "   - Variance estimation\n",
    "   - À-trous wavelet filter\n",
    "   - Edge-stopping (depth, normal, luminance)\n",
    "   - Variance-guided kernel size\n",
    "\n",
    "4. **ReSTIR**\n",
    "   - Weighted reservoir sampling\n",
    "   - Temporal reuse\n",
    "   - Spatial reuse\n",
    "   - Handles thousands of lights\n",
    "\n",
    "5. **Hybrid Rendering**\n",
    "   - G-buffer from rasterization\n",
    "   - Selective ray tracing\n",
    "   - Per-effect denoising\n",
    "   - Layer composition\n",
    "\n",
    "### Modern Games Using RT\n",
    "\n",
    "- **Metro Exodus**: Global illumination\n",
    "- **Control**: Reflections, GI, contact shadows\n",
    "- **Cyberpunk 2077**: Full RT lighting\n",
    "- **Minecraft RTX**: Path tracing\n",
    "- **Spider-Man**: Reflections\n",
    "\n",
    "### Performance Techniques\n",
    "\n",
    "✅ **1 SPP + denoising** instead of 100+ SPP  \n",
    "✅ **Half-resolution RT** upscaled  \n",
    "✅ **Temporal accumulation** for free samples  \n",
    "✅ **Checkerboard rendering** alternate pixels  \n",
    "✅ **Variable rate shading** less work in periphery  \n",
    "✅ **ReSTIR** for many lights  \n",
    "\n",
    "### Hardware Evolution\n",
    "\n",
    "**RTX 2000 series** (2018):\n",
    "- First RT cores\n",
    "- ~30 FPS at 1080p\n",
    "\n",
    "**RTX 3000 series** (2020):\n",
    "- 2x faster RT\n",
    "- 60 FPS at 1440p\n",
    "\n",
    "**RTX 4000 series** (2022):\n",
    "- 3rd gen RT cores\n",
    "- DLSS 3 (frame generation)\n",
    "- 60 FPS at 4K\n",
    "\n",
    "### Future Directions\n",
    "\n",
    "- **Neural rendering**: AI-based denoising (DLSS)\n",
    "- **Hybrid path tracing**: Offline quality in real-time\n",
    "- **Hardware ray tracing**: Dedicated silicon\n",
    "- **Coherent ray tracing**: Better GPU utilization\n",
    "- **Sparse ray tracing**: Adaptive sample distribution\n",
    "\n",
    "Real-time ray tracing is now practical and becoming standard in modern games and professional applications!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
