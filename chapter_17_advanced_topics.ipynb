{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 17: Advanced Topics\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/adiel2012/computer-vision/blob/main/chapter_17_advanced_topics.ipynb)\n",
    "\n",
    "**Advanced rendering topics** cover cutting-edge techniques used in production renderers. This chapter explores photon mapping, bidirectional path tracing, Metropolis light transport, and modern denoising methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from typing import Tuple, List, Optional\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Photon Mapping\n",
    "\n",
    "**Photon mapping** is a two-pass algorithm for global illumination.\n",
    "\n",
    "### Pass 1: Photon Tracing\n",
    "\n",
    "Emit photons from lights and trace through scene:\n",
    "\n",
    "1. Emit photon from light with power $\\Phi$\n",
    "2. Trace through scene, storing at diffuse surfaces\n",
    "3. Russian roulette for absorption/reflection\n",
    "4. Build photon map (k-d tree)\n",
    "\n",
    "### Pass 2: Rendering\n",
    "\n",
    "Ray trace from camera, estimating radiance using photon map:\n",
    "\n",
    "$$\n",
    "L_r(\\mathbf{x}, \\omega_o) \\approx \\frac{1}{\\pi r^2} \\sum_{p=1}^n \\Phi_p \\cdot f_r(\\mathbf{x}, \\omega_p, \\omega_o)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $n$ = number of nearest photons\n",
    "- $r$ = radius containing $n$ photons\n",
    "- $\\Phi_p$ = photon power\n",
    "- $f_r$ = BRDF\n",
    "\n",
    "### Caustic Photon Map\n",
    "\n",
    "Separate map for specular→diffuse paths (caustics):\n",
    "- More photons concentrated in caustic regions\n",
    "- Smaller search radius for sharper caustics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Photon:\n",
    "    \"\"\"Photon with position, direction, and power\"\"\"\n",
    "    position: np.ndarray  # 3D position\n",
    "    direction: np.ndarray  # Incoming direction\n",
    "    power: np.ndarray  # RGB power\n",
    "\n",
    "class PhotonMap:\n",
    "    \"\"\"Simple photon map with k-nearest neighbor search\"\"\"\n",
    "    def __init__(self, max_photons: int = 100000):\n",
    "        self.photons = []\n",
    "        self.max_photons = max_photons\n",
    "    \n",
    "    def store(self, photon: Photon):\n",
    "        \"\"\"Store photon in map\"\"\"\n",
    "        if len(self.photons) < self.max_photons:\n",
    "            self.photons.append(photon)\n",
    "    \n",
    "    def find_nearest(self, position: np.ndarray, max_dist: float, max_photons: int) -> List[Photon]:\n",
    "        \"\"\"Find nearest photons (simple linear search for demo)\"\"\"\n",
    "        distances = []\n",
    "        for photon in self.photons:\n",
    "            dist = np.linalg.norm(photon.position - position)\n",
    "            if dist < max_dist:\n",
    "                distances.append((dist, photon))\n",
    "        \n",
    "        distances.sort(key=lambda x: x[0])\n",
    "        return [p for _, p in distances[:max_photons]]\n",
    "    \n",
    "    def estimate_radiance(self, position: np.ndarray, normal: np.ndarray, \n",
    "                         max_dist: float = 0.5, num_photons: int = 50) -> np.ndarray:\n",
    "        \"\"\"Estimate radiance at surface point\"\"\"\n",
    "        photons = self.find_nearest(position, max_dist, num_photons)\n",
    "        \n",
    "        if len(photons) == 0:\n",
    "            return np.zeros(3)\n",
    "        \n",
    "        # Find radius of search sphere\n",
    "        max_r = 0\n",
    "        for p in photons:\n",
    "            r = np.linalg.norm(p.position - position)\n",
    "            max_r = max(max_r, r)\n",
    "        \n",
    "        # Density estimation\n",
    "        radiance = np.zeros(3)\n",
    "        for p in photons:\n",
    "            # Lambertian BRDF: cos(theta) / pi\n",
    "            cos_theta = max(0, np.dot(normal, -p.direction))\n",
    "            radiance += p.power * cos_theta\n",
    "        \n",
    "        # Normalize by area\n",
    "        area = math.pi * max_r * max_r\n",
    "        if area > 0:\n",
    "            radiance /= area\n",
    "        \n",
    "        return radiance\n",
    "\n",
    "print(\"✓ Photon mapping loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bidirectional Path Tracing (BDPT)\n",
    "\n",
    "**BDPT** traces paths from both camera and light, connecting them.\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "1. **Eye subpath**: Trace from camera $s_0, s_1, ..., s_k$\n",
    "2. **Light subpath**: Trace from light $t_0, t_1, ..., t_l$\n",
    "3. **Connect**: Try all combinations $(s_i, t_j)$\n",
    "4. **MIS weights**: Combine using multiple importance sampling\n",
    "\n",
    "### Path Contribution\n",
    "\n",
    "For connected path $\\bar{\\mathbf{x}}_{s,t}$ with $s$ eye vertices and $t$ light vertices:\n",
    "\n",
    "$$\n",
    "C_{s,t} = \\alpha_{s,t} \\cdot f(\\bar{\\mathbf{x}}_{s,t}) \\cdot G(s_s \\leftrightarrow t_t) \\cdot w_{s,t}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\alpha_{s,t}$ = throughput product\n",
    "- $f$ = path contribution (light × BRDF × geometry)\n",
    "- $G$ = connection geometry term\n",
    "- $w_{s,t}$ = MIS weight\n",
    "\n",
    "### MIS Weight (Balance Heuristic)\n",
    "\n",
    "$$\n",
    "w_{s,t} = \\frac{p_{s,t}}{\\sum_{i=0}^{s+t} p_i}\n",
    "$$\n",
    "\n",
    "Optimally combines all sampling strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BDPT conceptual implementation\n",
    "class PathVertex:\n",
    "    \"\"\"Vertex in a light transport path\"\"\"\n",
    "    def __init__(self, position, normal, throughput, pdf):\n",
    "        self.position = position  # 3D position\n",
    "        self.normal = normal      # Surface normal\n",
    "        self.throughput = throughput  # Path throughput\n",
    "        self.pdf = pdf  # Path PDF\n",
    "\n",
    "def trace_eye_subpath(origin, direction, max_depth=5):\n",
    "    \"\"\"Trace subpath from camera (conceptual)\"\"\"\n",
    "    path = []\n",
    "    # Start from camera\n",
    "    # Trace through scene, building vertex list\n",
    "    # Each bounce adds a vertex with position, normal, throughput, PDF\n",
    "    return path\n",
    "\n",
    "def trace_light_subpath(light_position, max_depth=5):\n",
    "    \"\"\"Trace subpath from light (conceptual)\"\"\"\n",
    "    path = []\n",
    "    # Start from light\n",
    "    # Emit in random direction\n",
    "    # Trace through scene, building vertex list\n",
    "    return path\n",
    "\n",
    "def connect_bdpt(eye_path, light_path, s, t):\n",
    "    \"\"\"Connect s-th eye vertex with t-th light vertex (conceptual)\"\"\"\n",
    "    if s >= len(eye_path) or t >= len(light_path):\n",
    "        return 0\n",
    "    \n",
    "    eye_vertex = eye_path[s]\n",
    "    light_vertex = light_path[t]\n",
    "    \n",
    "    # Check visibility\n",
    "    # Compute geometry term\n",
    "    # Evaluate BRDFs\n",
    "    # Compute MIS weight\n",
    "    # Return path contribution\n",
    "    \n",
    "    return 0  # Placeholder\n",
    "\n",
    "def bidirectional_path_trace(camera_ray, scene):\n",
    "    \"\"\"Full BDPT pixel estimate (conceptual)\"\"\"\n",
    "    radiance = np.zeros(3)\n",
    "    \n",
    "    # Trace eye subpath\n",
    "    eye_path = trace_eye_subpath(camera_ray.origin, camera_ray.direction)\n",
    "    \n",
    "    # Trace light subpath\n",
    "    light_path = trace_light_subpath(scene.lights[0].position)\n",
    "    \n",
    "    # Try all connections (s,t) where s+t <= max_depth\n",
    "    max_depth = 5\n",
    "    for s in range(len(eye_path) + 1):\n",
    "        for t in range(len(light_path) + 1):\n",
    "            if s + t > max_depth:\n",
    "                continue\n",
    "            contribution = connect_bdpt(eye_path, light_path, s, t)\n",
    "            radiance += contribution\n",
    "    \n",
    "    return radiance\n",
    "\n",
    "print(\"✓ BDPT concepts loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Metropolis Light Transport (MLT)\n",
    "\n",
    "**MLT** uses Markov Chain Monte Carlo to explore path space.\n",
    "\n",
    "### Metropolis-Hastings Algorithm\n",
    "\n",
    "1. Start with seed path $\\bar{\\mathbf{x}}_0$\n",
    "2. Propose mutation $\\bar{\\mathbf{x}}' = T(\\bar{\\mathbf{x}}_i)$\n",
    "3. Accept with probability:\n",
    "$$\n",
    "a(\\bar{\\mathbf{x}}_i \\to \\bar{\\mathbf{x}}') = \\min\\left(1, \\frac{f(\\bar{\\mathbf{x}}') T(\\bar{\\mathbf{x}}' \\to \\bar{\\mathbf{x}}_i)}{f(\\bar{\\mathbf{x}}_i) T(\\bar{\\mathbf{x}}_i \\to \\bar{\\mathbf{x}}')}\\right)\n",
    "$$\n",
    "4. If accepted: $\\bar{\\mathbf{x}}_{i+1} = \\bar{\\mathbf{x}}'$, else: $\\bar{\\mathbf{x}}_{i+1} = \\bar{\\mathbf{x}}_i$\n",
    "\n",
    "### Mutation Strategies\n",
    "\n",
    "- **Small step**: Perturb existing vertex positions\n",
    "- **Large step**: Generate completely new path\n",
    "- **Caustic perturbation**: Preserve specular sub-paths\n",
    "- **Lens perturbation**: Change camera ray direction\n",
    "\n",
    "### Advantages\n",
    "\n",
    "- Automatic importance sampling\n",
    "- Excellent for difficult light transport (caustics, indirect)\n",
    "- Explores path space efficiently\n",
    "\n",
    "### Disadvantages\n",
    "\n",
    "- Slow startup\n",
    "- Can produce structured noise\n",
    "- Difficult to parallelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLT conceptual framework\n",
    "class Path:\n",
    "    \"\"\"Light transport path\"\"\"\n",
    "    def __init__(self, vertices, contribution):\n",
    "        self.vertices = vertices  # List of vertices\n",
    "        self.contribution = contribution  # f(path)\n",
    "\n",
    "def mutate_small_step(path):\n",
    "    \"\"\"Small perturbation mutation\"\"\"\n",
    "    # Perturb random vertex position slightly\n",
    "    # Recompute affected sub-path\n",
    "    # Return new path\n",
    "    return path  # Placeholder\n",
    "\n",
    "def mutate_large_step(scene):\n",
    "    \"\"\"Large step mutation - generate new path\"\"\"\n",
    "    # Generate completely new path\n",
    "    # Trace from camera with random direction\n",
    "    return None  # Placeholder\n",
    "\n",
    "def metropolis_sample(scene, num_mutations=10000):\n",
    "    \"\"\"Metropolis light transport (conceptual)\"\"\"\n",
    "    # Generate initial path\n",
    "    current_path = None  # Start with seed\n",
    "    samples = []\n",
    "    \n",
    "    for i in range(num_mutations):\n",
    "        # Choose mutation type\n",
    "        if random.random() < 0.3:  # 30% large step\n",
    "            proposed = mutate_large_step(scene)\n",
    "            T_forward = 0.3\n",
    "            T_backward = 0.3\n",
    "        else:  # 70% small step\n",
    "            proposed = mutate_small_step(current_path)\n",
    "            T_forward = 0.7\n",
    "            T_backward = 0.7\n",
    "        \n",
    "        # Metropolis acceptance\n",
    "        if proposed is None:\n",
    "            continue\n",
    "        \n",
    "        # Acceptance probability\n",
    "        a = min(1.0, (proposed.contribution * T_backward) / \n",
    "                     (current_path.contribution * T_forward))\n",
    "        \n",
    "        if random.random() < a:\n",
    "            current_path = proposed\n",
    "        \n",
    "        samples.append(current_path)\n",
    "    \n",
    "    return samples\n",
    "\n",
    "print(\"✓ MLT concepts loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image-Based Lighting (IBL)\n",
    "\n",
    "**IBL** uses environment maps for lighting.\n",
    "\n",
    "### Environment Map Sampling\n",
    "\n",
    "1. **Uniform sampling**: Sample random direction on sphere\n",
    "2. **Importance sampling**: Sample proportional to luminance\n",
    "3. **Stratified sampling**: Divide sphere into strata\n",
    "\n",
    "### Importance Sampling Strategy\n",
    "\n",
    "Build 2D CDF from environment map:\n",
    "\n",
    "$$\n",
    "p(\\theta, \\phi) = \\frac{L(\\theta, \\phi) \\sin\\theta}{\\int_0^{2\\pi} \\int_0^\\pi L(\\theta', \\phi') \\sin\\theta' \\, d\\theta' d\\phi'}\n",
    "$$\n",
    "\n",
    "Sample using inversion method.\n",
    "\n",
    "### Spherical Harmonics (SH) Lighting\n",
    "\n",
    "Represent environment as SH coefficients:\n",
    "\n",
    "$$\n",
    "L(\\mathbf{d}) \\approx \\sum_{l=0}^n \\sum_{m=-l}^l c_{lm} Y_{lm}(\\mathbf{d})\n",
    "$$\n",
    "\n",
    "Fast evaluation, good for diffuse lighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_environment_map_uniform(env_map):\n",
    "    \"\"\"Uniformly sample direction on sphere\"\"\"\n",
    "    # Random spherical coordinates\n",
    "    u = random.random()\n",
    "    v = random.random()\n",
    "    \n",
    "    theta = math.acos(1 - 2 * u)  # [0, pi]\n",
    "    phi = 2 * math.pi * v  # [0, 2pi]\n",
    "    \n",
    "    # Convert to Cartesian\n",
    "    x = math.sin(theta) * math.cos(phi)\n",
    "    y = math.sin(theta) * math.sin(phi)\n",
    "    z = math.cos(theta)\n",
    "    \n",
    "    direction = np.array([x, y, z])\n",
    "    \n",
    "    # Look up environment map\n",
    "    u_tex = phi / (2 * math.pi)\n",
    "    v_tex = theta / math.pi\n",
    "    \n",
    "    # Sample env map at (u_tex, v_tex)\n",
    "    # ...\n",
    "    \n",
    "    return direction, 1.0 / (4 * math.pi)  # direction, pdf\n",
    "\n",
    "def build_env_map_cdf(env_map):\n",
    "    \"\"\"Build cumulative distribution for importance sampling\"\"\"\n",
    "    height, width = env_map.shape[:2]\n",
    "    \n",
    "    # Compute luminance for each pixel\n",
    "    luminance = np.zeros((height, width))\n",
    "    for j in range(height):\n",
    "        theta = (j + 0.5) / height * math.pi\n",
    "        sin_theta = math.sin(theta)\n",
    "        for i in range(width):\n",
    "            rgb = env_map[j, i]\n",
    "            lum = 0.2126 * rgb[0] + 0.7152 * rgb[1] + 0.0722 * rgb[2]\n",
    "            luminance[j, i] = lum * sin_theta\n",
    "    \n",
    "    # Build marginal CDF (rows)\n",
    "    marginal = np.sum(luminance, axis=1)\n",
    "    marginal_cdf = np.cumsum(marginal)\n",
    "    marginal_cdf /= marginal_cdf[-1]\n",
    "    \n",
    "    # Build conditional CDF (columns given row)\n",
    "    conditional_cdf = np.cumsum(luminance, axis=1)\n",
    "    for j in range(height):\n",
    "        if conditional_cdf[j, -1] > 0:\n",
    "            conditional_cdf[j] /= conditional_cdf[j, -1]\n",
    "    \n",
    "    return marginal_cdf, conditional_cdf\n",
    "\n",
    "print(\"✓ IBL sampling loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Denoising Techniques\n",
    "\n",
    "Modern renderers use **denoising** to reduce Monte Carlo noise.\n",
    "\n",
    "### Edge-Avoiding À-Trous Wavelet\n",
    "\n",
    "Multi-scale filter preserving edges:\n",
    "\n",
    "$$\n",
    "I^{(l+1)}(\\mathbf{p}) = \\sum_{\\mathbf{q} \\in \\Omega} h(\\mathbf{q}) \\cdot w(\\mathbf{p}, \\mathbf{q}) \\cdot I^{(l)}(\\mathbf{p} + 2^l \\mathbf{q})\n",
    "$$\n",
    "\n",
    "Weight function:\n",
    "$$\n",
    "w(\\mathbf{p}, \\mathbf{q}) = w_c \\cdot w_n \\cdot w_d\n",
    "$$\n",
    "\n",
    "- $w_c$: color similarity\n",
    "- $w_n$: normal similarity  \n",
    "- $w_d$: depth similarity\n",
    "\n",
    "### SVGF (Spatiotemporal Variance-Guided Filtering)\n",
    "\n",
    "1. **Temporal accumulation**: Blend with previous frame\n",
    "2. **Variance estimation**: Track sample variance\n",
    "3. **Spatial filtering**: À-trous with variance-based kernel\n",
    "4. **Edge-stopping**: Use G-buffer (normals, depth, albedo)\n",
    "\n",
    "### Neural Denoising\n",
    "\n",
    "Machine learning approaches:\n",
    "- Train CNN on noisy/clean pairs\n",
    "- Use auxiliary features (normals, albedo, depth)\n",
    "- Real-time capable (DLSS, OptiX denoiser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def gaussian_kernel_1d(sigma, size):\n    \"\"\"1D Gaussian kernel\"\"\"\n    kernel = np.zeros(size)\n    center = size // 2\n    sum_val = 0\n    \n    for i in range(size):\n        x = i - center\n        kernel[i] = math.exp(-(x * x) / (2 * sigma * sigma))\n        sum_val += kernel[i]\n    \n    return kernel / sum_val\n\ndef bilateral_filter_simple(image, sigma_spatial=2.0, sigma_range=0.1):\n    \"\"\"Simple bilateral filter for denoising\"\"\"\n    height, width = image.shape[:2]\n    result = np.zeros_like(image)\n    \n    kernel_size = int(3 * sigma_spatial)\n    \n    print(f\"  Processing {height}x{width} image with kernel size {kernel_size*2+1}x{kernel_size*2+1}\")\n    \n    for y in range(height):\n        if y % 64 == 0:\n            progress = (y / height) * 100\n            print(f\"  Progress: {progress:.1f}% (row {y}/{height})\")\n        \n        for x in range(width):\n            center_color = image[y, x]\n            \n            sum_weight = 0\n            sum_color = np.zeros(3)\n            \n            for dy in range(-kernel_size, kernel_size + 1):\n                for dx in range(-kernel_size, kernel_size + 1):\n                    ny = np.clip(y + dy, 0, height - 1)\n                    nx = np.clip(x + dx, 0, width - 1)\n                    \n                    neighbor_color = image[ny, nx]\n                    \n                    # Spatial weight\n                    spatial_dist2 = dx * dx + dy * dy\n                    w_spatial = math.exp(-spatial_dist2 / (2 * sigma_spatial * sigma_spatial))\n                    \n                    # Range weight (color similarity)\n                    color_dist2 = np.sum((center_color - neighbor_color) ** 2)\n                    w_range = math.exp(-color_dist2 / (2 * sigma_range * sigma_range))\n                    \n                    weight = w_spatial * w_range\n                    \n                    sum_weight += weight\n                    sum_color += weight * neighbor_color\n            \n            if sum_weight > 0:\n                result[y, x] = sum_color / sum_weight\n            else:\n                result[y, x] = center_color\n    \n    print(\"  Progress: 100.0% (complete)\")\n    return result\n\nprint(\"✓ Denoising loaded\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Simple Denoising Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create test image with noise\ndef create_noisy_gradient():\n    \"\"\"Create smooth gradient with Monte Carlo noise\"\"\"\n    size = 256\n    image = np.zeros((size, size, 3))\n    \n    print(\"Creating noisy test image...\")\n    for y in range(size):\n        if y % 64 == 0:\n            print(f\"  Generating row {y}/{size}\")\n        for x in range(size):\n            # Smooth gradient\n            base_color = np.array([\n                x / size,\n                y / size,\n                (x + y) / (2 * size)\n            ])\n            \n            # Add Monte Carlo noise (simulating low sample count)\n            noise = np.random.normal(0, 0.1, 3)\n            \n            image[y, x] = np.clip(base_color + noise, 0, 1)\n    \n    print(\"✓ Noisy image created\")\n    return image\n\n# Create noisy image\nprint(\"=\"*70)\nprint(\"DENOISING DEMONSTRATION\")\nprint(\"=\"*70)\nnp.random.seed(42)\nnoisy = create_noisy_gradient()\n\n# Denoise\nprint(\"\\nApplying bilateral filter denoising...\")\nprint(\"  Parameters: sigma_spatial=3.0, sigma_range=0.15\")\ndenoised = bilateral_filter_simple(noisy, sigma_spatial=3.0, sigma_range=0.15)\nprint(\"✓ Denoising complete!\")\n\n# Visualize\nfig, axes = plt.subplots(1, 2, figsize=(12, 6))\n\naxes[0].imshow(noisy)\naxes[0].set_title('Noisy Rendering (Low SPP)', fontsize=12, fontweight='bold')\naxes[0].axis('off')\n\naxes[1].imshow(denoised)\naxes[1].set_title('Bilateral Filtered (Denoised)', fontsize=12, fontweight='bold')\naxes[1].axis('off')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"Bilateral filter successfully removes noise while preserving edges!\")\nprint(\"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Advanced rendering techniques** used in production:\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Photon Mapping**\n",
    "   - Two-pass algorithm\n",
    "   - Excellent for caustics\n",
    "   - k-d tree photon storage\n",
    "   - Density estimation\n",
    "\n",
    "2. **Bidirectional Path Tracing (BDPT)**\n",
    "   - Traces from camera AND light\n",
    "   - All path lengths simultaneously\n",
    "   - Multiple importance sampling (MIS)\n",
    "   - Better than unidirectional PT for complex scenes\n",
    "\n",
    "3. **Metropolis Light Transport (MLT)**\n",
    "   - Markov Chain Monte Carlo\n",
    "   - Automatic importance sampling\n",
    "   - Explores difficult paths\n",
    "   - Mutation strategies\n",
    "\n",
    "4. **Image-Based Lighting (IBL)**\n",
    "   - Environment maps for lighting\n",
    "   - Importance sampling\n",
    "   - Spherical harmonics\n",
    "   - Fast diffuse lighting\n",
    "\n",
    "5. **Denoising**\n",
    "   - Bilateral filter: edge-preserving\n",
    "   - À-trous wavelet: multi-scale\n",
    "   - SVGF: spatiotemporal\n",
    "   - Neural denoising: ML-based\n",
    "\n",
    "### Production Usage\n",
    "\n",
    "- **Photon Mapping**: Caustics in glass, water\n",
    "- **BDPT**: Complex indirect lighting\n",
    "- **MLT**: Difficult scenes (e.g., light through keyhole)\n",
    "- **IBL**: Outdoor scenes, studio lighting\n",
    "- **Denoising**: All real-time ray tracing\n",
    "\n",
    "### Modern Renderers\n",
    "\n",
    "- **Arnold**: BDPT + importance sampling\n",
    "- **V-Ray**: Multiple algorithms selectable\n",
    "- **RenderMan**: Path tracing + importance sampling\n",
    "- **Cycles**: Unidirectional PT + MIS\n",
    "- **Real-time**: Ray tracing + denoising (DLSS, SVGF)\n",
    "\n",
    "These advanced techniques enable production-quality rendering for film, games, and visualization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}